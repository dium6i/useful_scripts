'''
Author: ChatGPT, Wei Qin
Date: 2023-12-29
Description:
    Use SIFT and flann matcher to find duplicate images.
    Partially generated by ChatGPT and edited by me.
Update Log:
    2023-12-29: File created.

'''

import concurrent.futures
import os
import time

import cv2
from tqdm import tqdm


def fun_time(func):
    '''
    Record function running time.
    '''
    def wrapper(*args, **kwargs):
        t1 = time.time()
        result = func(*args, **kwargs)
        t2 = time.time() - t1
        print(f'{func.__name__} ran in {t2:.2f} seconds.')

        return result

    return wrapper


@fun_time
def calculate_dataset_descriptors(dataset, sift):
    '''
    Use SIFT to calculate descriptors of every images in dataset.

    Args:
        dataset (string): Dataset directory.
        sift (cv2.SIFT): SIFT detector.

    Returns:
        image_descriptors (dict): Results of every image and its descriptors.
    '''
    image_descriptors = {}
    image_list = os.listdir(dataset)

    # Define function processing a single image.
    def process_image(image):
        img = cv2.imread(os.path.join(dataset, image))
        if img is None:
            return image, None

        # Process images.
        h, w, c = img.shape
        if h > w:  # Portrait
            img = cv2.resize(img, (768, 1024))
        elif w > h:  # Landscape
            img = cv2.resize(img, (1024, 768))
        else:  # Square
            img = cv2.resize(img, (768, 768))

        # Use GaussianBlur to reduce the effect of moiré as much as possible.
        img = cv2.GaussianBlur(img, (9, 9), 2)
        keypoints, descriptors = sift.detectAndCompute(img, None)

        return image, descriptors

    # Process each image in parallel using a thread pool.
    with concurrent.futures.ThreadPoolExecutor() as executor:
        # Submit all image processing tasks.
        future_to_image = {
            executor.submit(process_image, image): image
            for image in image_list
        }

        with tqdm(total=len(image_list), desc='Calculating Descriptors') as progress:
            # Get and process results.
            for future in concurrent.futures.as_completed(future_to_image):
                image, descriptors = future.result()
                if descriptors is not None:
                    image_descriptors[image] = descriptors

                progress.update(1)

    return image_descriptors


def initialize_flann_matcher():
    '''
    Initialize flann matcher.

    Args:
        None.

    Returns:
        flann (cv2.FlannBasedMatcher): Flann matcher.
    '''
    FLANN_INDEX_KDTREE = 1
    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
    search_params = dict(checks=50)  # or pass an empty dictionary
    flann = cv2.FlannBasedMatcher(index_params, search_params)

    return flann


def flann_match(flann, descriptors1, descriptors2):
    '''
    Use flann matcher to compare two descriptors.

    Args:
        flann (cv2.FlannBasedMatcher): Flann matcher.
        descriptors1 (numpy.ndarray): Descriptors of first image.
        descriptors2 (numpy.ndarray): Descriptors of second image.

    Returns:
        good_matches (list): Results of good matches.
    '''
    matches = flann.knnMatch(descriptors1, descriptors2, k=2)

    # Filter out good matches
    good_matches = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)

    return good_matches


@fun_time
def one_to_all(descriptors0, image_descriptors, flann):
    '''
    Compare with descriptors of every image in dataset.

    Args:
        descriptors0 (numpy.ndarray): Descriptors of target image.
        image_descriptors (dict): Results of every image and its descriptors.
        flann (cv2.FlannBasedMatcher): Flann matcher.

    Returns:
        similar_images (dict): Comparison results to every image in dataset.
    '''
    similar_images = {}

    # Define function comparing two descriptors.
    def compare_with_single_image(image_name, image_descriptor):
        good_matches = flann_match(flann, descriptors0, image_descriptor)
        return image_name, len(good_matches)

    # Process comparisons with all images in parallel using a thread pool.
    with concurrent.futures.ThreadPoolExecutor() as executor:
        # Submit all image comparisons tasks.
        future_to_image = {
            executor.submit(compare_with_single_image, k, v): k
            for k, v in image_descriptors.items()
        }

        with tqdm(total=len(image_descriptors), desc='Comparing Images') as progress:
            # Get and process results
            for future in concurrent.futures.as_completed(future_to_image):
                image_name, match_count = future.result()
                similar_images[image_name] = match_count
                progress.update(1)

    return similar_images


@fun_time
def all_to_all(image_descriptors, flann, threshold):
    '''
    Find duplicate images in dataset.

    Args:
        image_descriptors (dict): Results of every image and its descriptors.
        flann (cv2.FlannBasedMatcher): Flann matcher.
        threshold (int): Threshold to determine whether images are similar.

    Returns:
        similar_images (dict): Comparison results of whole dataset.
    '''
    similar_images = {}
    image_list = list(image_descriptors.keys())
    descriptors_list = list(image_descriptors.values())

    # Define functions processing single image pairs.
    def process_image_pair(i, j):
        descriptors1 = descriptors_list[i]
        descriptors2 = descriptors_list[j]
        good_matches = flann_match(flann, descriptors1, descriptors2)
        if len(good_matches) > threshold:
            return image_list[i], image_list[j]

        return None

    # Process all image pairs in parallel using a thread pool.
    with concurrent.futures.ThreadPoolExecutor() as executor:
        future_to_pair = {
            executor.submit(process_image_pair, i, j): (i, j)
            for i in range(len(image_list))
            for j in range(i + 1, len(image_list))
        }

        total_pairs = int(len(image_list) * (len(image_list) - 1) / 2)
        with tqdm(total=total_pairs, desc='Comparing Image Pairs') as progress:
            for future in concurrent.futures.as_completed(future_to_pair):
                result = future.result()
                if result:
                    image1, image2 = result
                    if image1 not in similar_images:
                        similar_images[image1] = []
                    similar_images[image1].append(image2)
                progress.update(1)

    return similar_images


@fun_time
def merge_lists_if_intersect(lists):
    '''
    Merges any two lists within the given list if they have an intersection.
    Removes duplicates in the process.

    Args:
        lists (list): List to be processed.

    Returns:
        lists (list): List processed.
    '''
    merged = True
    while merged:
        merged = False
        result = []
        while lists:
            current = lists.pop()
            for i, lst in enumerate(lists):
                # Check if there is an intersection
                if set(current).intersection(lst):
                    # Merge and remove duplicates
                    current = list(set(current + lst))
                    lists.pop(i)
                    merged = True
                    break
            result.append(sorted(current))
        lists = result

    return lists


if __name__ == '__main__':
    # Setting parameters
    img_file = '/path/of/image.jpg'  # Path of image
    dataset = '/path/of/dataset'  # Dataset directory
    within_dataset = True  # Whether to compare within dataset
    threshold = 300  # Good matches

    # Initialize SIFT detector and flann matcher
    sift = cv2.SIFT_create()
    flann = initialize_flann_matcher()

    image_descriptors = calculate_dataset_descriptors(dataset, sift)

    if within_dataset:
        results = all_to_all(image_descriptors, flann, threshold)

        similar_images = []
        for image_name, similar_list in results.items():
            similar_list.append(image_name)
            similar_images.append(sorted(similar_list))

        similar_images = merge_lists_if_intersect(similar_images)
        print('Groups of similar images: ')
        for i in similar_images:
            print(i)

    else:
        img0 = cv2.imread(img_file)
        # Use GaussianBlur to reduce the effect of moiré as much as possible.
        img0 = cv2.GaussianBlur(img0, (9, 9), 2)
        keypoints0, descriptors0 = sift.detectAndCompute(img0, None)

        results = one_to_all(descriptors0, image_descriptors, flann)
        similar_images = [k for k, v in results.items() if v > threshold]

        img_name = img_file.split('/')[-1]
        print(f'"{img_name}" is similar to: \n{similar_images}')
