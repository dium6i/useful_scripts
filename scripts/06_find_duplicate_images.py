'''
Author: ChatGPT, Wei Qin
Date: 2023-12-29
Description:
    Use SIFT and flann matcher to find duplicate images.
    Partially generated by ChatGPT and edited by me.
Update Log:
    2023-12-29: File created. 
    2023-12-29: Added features to save results and 
                improved comparison speed. 
    2023-12-30: Changed some import methods and modified 
                the corresponding code format. 
    2024-01-05: Added a comment. 
    2024-01-07: Changed some parameters to speed up. 

'''

from concurrent.futures import ThreadPoolExecutor, as_completed
import os
import shutil
import time

import cv2
from tqdm import tqdm


def fun_time(func):
    '''
    Record function running time.
    '''
    def wrapper(*args, **kwargs):
        t1 = time.time()
        result = func(*args, **kwargs)
        t2 = time.time() - t1
        print(f'{func.__name__} ran in {t2:.2f} seconds.')

        return result

    return wrapper


def initialize_flann_matcher():
    '''
    Initialize flann matcher.

    Args:
        None.

    Returns:
        flann (cv2.FlannBasedMatcher): Flann matcher.
    '''
    FLANN_INDEX_KDTREE = 1
    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
    search_params = dict(checks=20)  # or pass an empty dictionary
    flann = cv2.FlannBasedMatcher(index_params, search_params)

    return flann


@fun_time
def calculate_dataset_descriptors(dataset, sift):
    '''
    Use SIFT to calculate descriptors of every images in dataset.

    Args:
        dataset (string): Dataset directory.
        sift (cv2.SIFT): SIFT detector.

    Returns:
        image_descriptors (dict): Results of every image and its descriptors.
    '''
    image_descriptors = {}
    image_list = os.listdir(dataset)

    # Define function processing a single image.
    def process_image(image):
        img = cv2.imread(os.path.join(dataset, image))
        if img is None:
            return image, None

        # Process images.
        h, w, c = img.shape
        if h > w:  # Portrait
            img = cv2.resize(img, (384, 512))
        elif w > h:  # Landscape
            img = cv2.resize(img, (512, 384))
        else:  # Square
            img = cv2.resize(img, (384, 384))

        # Use GaussianBlur to reduce the effect of moiré as much as possible.
        img = cv2.GaussianBlur(img, (9, 9), 2)
        keypoints, descriptors = sift.detectAndCompute(img, None)

        return image, descriptors

    # Process each image in parallel using a thread pool.
    with ThreadPoolExecutor() as executor:
        # Submit all image processing tasks.
        future_to_image = {
            executor.submit(process_image, image): image
            for image in image_list
        }

        # Get and process results.
        for future in tqdm(
                as_completed(future_to_image), 
                total=len(image_list), 
                desc='Calculating Descriptors'):
            image, descriptors = future.result()
            if descriptors is not None:
                image_descriptors[image] = descriptors


    return image_descriptors


def flann_match(flann, descriptors1, descriptors2):
    '''
    Use flann matcher to compare two descriptors.

    Args:
        flann (cv2.FlannBasedMatcher): Flann matcher.
        descriptors1 (numpy.ndarray): Descriptors of first image.
        descriptors2 (numpy.ndarray): Descriptors of second image.

    Returns:
        good_matches (list): Results of good matches.
    '''
    matches = flann.knnMatch(descriptors1, descriptors2, k=2)

    # Filter out good matches
    good_matches = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)

    return good_matches


@fun_time
def all_to_all(image_descriptors, flann, threshold):
    '''
    Main process of compare_within_dataset().

    Args:
        image_descriptors (dict): Results of every image and its descriptors.
        flann (cv2.FlannBasedMatcher): Flann matcher.
        threshold (int): Threshold to determine whether images are similar.

    Returns:
        similar_images (dict): Comparison results of whole dataset.
    '''
    similar_images = {}
    image_list = list(image_descriptors.keys())
    descriptors_list = list(image_descriptors.values())

    # Define functions processing single image pairs.
    def process_image_pair(i, j):
        descriptors1 = descriptors_list[i]
        descriptors2 = descriptors_list[j]
        good_matches = flann_match(flann, descriptors1, descriptors2)
        if len(good_matches) > threshold:
            return image_list[i], image_list[j]

        return None

    # Process all image pairs in parallel using a thread pool.
    with ThreadPoolExecutor() as executor:
        future_to_pair = {
            executor.submit(process_image_pair, i, j): (i, j)
            for i in range(len(image_list))
            for j in range(i + 1, len(image_list))
        }

        # Get and process results
        total_pairs = int(len(image_list) * (len(image_list) - 1) / 2)
        for future in tqdm(
                as_completed(future_to_pair),
                total=total_pairs,
                desc='Comparing Image Pairs'):
            result = future.result()
            if result:
                image1, image2 = result
                if image1 not in similar_images:
                    similar_images[image1] = []
                similar_images[image1].append(image2)

    return similar_images


@fun_time
def one_to_all(descriptors0, image_descriptors, flann):
    '''
    Main process of compare_to_dataset().

    Args:
        descriptors0 (numpy.ndarray): Descriptors of target image.
        image_descriptors (dict): Results of every image and its descriptors.
        flann (cv2.FlannBasedMatcher): Flann matcher.

    Returns:
        similar_images (dict): Comparison results to every image in dataset.
    '''
    similar_images = {}

    # Define function comparing two descriptors.
    def compare_with_single_image(image_name, image_descriptor):
        good_matches = flann_match(flann, descriptors0, image_descriptor)
        return image_name, len(good_matches)

    # Process comparisons with all images in parallel using a thread pool.
    with ThreadPoolExecutor() as executor:
        # Submit all image comparisons tasks.
        future_to_image = {
            executor.submit(compare_with_single_image, k, v): k
            for k, v in image_descriptors.items()
        }

        # Get and process results
        for future in tqdm(
                as_completed(future_to_image), 
                total=len(image_descriptors), 
                desc='Comparing Images'):
            image_name, match_count = future.result()
            similar_images[image_name] = match_count
            progress.update(1)

    return similar_images


@fun_time
def merge_lists_if_intersect(lists):
    '''
    Merges any two lists within the given list if they have an intersection.
    Removes duplicates in the process.

    Args:
        lists (list): List to be processed.

    Returns:
        lists (list): List processed.
    '''
    merged = True
    while merged:
        merged = False
        result = []
        while lists:
            current = lists.pop()
            for i, lst in enumerate(lists):
                # Check if there is an intersection
                if set(current).intersection(lst):
                    # Merge and remove duplicates
                    current = list(set(current + lst))
                    lists.pop(i)
                    merged = True
                    break
            result.append(sorted(current))
        lists = result

    return lists


def compare_within_dataset(params, flann, image_descriptors):
    '''
    Find duplicate images in dataset.
    Organize, show and save results.

    Args:
        params (dict): Parameters.
        flann (cv2.FlannBasedMatcher): Flann matcher.
        image_descriptors (dict): Results of every image and its descriptors.

    Returns:
        None.
    '''
    results = all_to_all(image_descriptors, flann, params['threshold'])

    similar_images = []
    for image_name, similar_list in results.items():
        similar_list.append(image_name)
        similar_images.append(sorted(similar_list))

    similar_images = merge_lists_if_intersect(similar_images)
    groups = len(similar_images)
    print(f'{groups} groups of similar images: ')

    for i in range(1, groups + 1):
        if params['save_results']:
            group_dir = os.path.join(params['save_dir'], f'group_{i:03d}')
            if not os.path.exists(group_dir):
                os.makedirs(group_dir)
            for j in similar_images[i - 1]:
                shutil.copyfile(
                    os.path.join(params['dataset'], j), 
                    os.path.join(group_dir, j)
                    )
        print(similar_images[i - 1])


def compare_to_dataset(params, sift, image_descriptors, flann):
    '''
    Compare with descriptors of every image in dataset.

    Args:
        params (dict): Parameters.
        sift (cv2.SIFT): SIFT detector.
        image_descriptors (dict): Results of every image and its descriptors.
        flann (cv2.FlannBasedMatcher): Flann matcher.

    Returns:
        None.
    '''
    img0 = cv2.imread(params['img_file'])
    # Use GaussianBlur to reduce the effect of moiré as much as possible.
    img0 = cv2.GaussianBlur(img0, (9, 9), 2)
    keypoints0, descriptors0 = sift.detectAndCompute(img0, None)

    results = one_to_all(descriptors0, image_descriptors, flann)
    similar_images = [k for k, v in results.items() if v > params['threshold']]

    snippets = params['img_file'].split('/')
    if len(snippets) < 2:
        snippets = params['img_file'].split('\\')

    print(f'"{snippets[-1]}" is similar to: \n{similar_images}')
    if params['save_results']:
        if not os.path.exists(params['save_dir']):
            os.mkdir(params['save_dir'])
        for i in similar_images:
            shutil.copyfile(
                os.path.join(params['dataset'], i), 
                os.path.join(params['save_dir'], i)
                )


def run(params):
    '''
    Main process.

    Args:
        params (dict): Parameters.

    Returns:
        None.
    '''
    # Initialize SIFT detector and flann matcher
    sift = cv2.SIFT_create()
    flann = initialize_flann_matcher()

    image_descriptors = calculate_dataset_descriptors(params['dataset'], sift)

    if params['within_dataset']:
        compare_within_dataset(params, flann, image_descriptors)

    else:
        compare_to_dataset(params, sift, image_descriptors, flann)


if __name__ == '__main__':
    # Setting parameters
    params = {
        'img_file': '/path/of/image.jpg',  # Path of image
        'dataset': '/path/of/dataset',  # Dataset directory
        'save_dir': '/path/to/save',  # Where to save result
        'save_results': True,  # Whether to save comparison results
        'within_dataset': True,  # Whether to compare within dataset
        'threshold': 150  # Good matches
    }

    run(params)
